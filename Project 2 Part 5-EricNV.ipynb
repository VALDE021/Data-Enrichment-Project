{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2104dc01-2922-4bd6-bf11-2471420ee4db",
   "metadata": {},
   "source": [
    "# <u><center>Project 2 Part 5 Core\n",
    "- Authored by: Eric N. Valdez\n",
    "- Date: 4/6/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572aabd-189a-41fa-a705-cca644a39a76",
   "metadata": {},
   "source": [
    "## `Sentiment Analysis and Rating Prediction of Moving Reviews`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7c166-768a-4d5d-b26c-b74963366a41",
   "metadata": {},
   "source": [
    "### <u>Overview:\n",
    "- This project is an extension of the movies porject from Enricment. This portion focuses on applying Natural Language Processing (NLP) techniques to analyze a database of movie reviews.\n",
    "- Students will leverage NLP tools such as NLTK, Spacy, WordCloud, and Scikit-Learn to explore, analyze, and model text data. The ultimate goal is to establish a relationship between the textual content of the reviews and their associated ratings and subsequently predict these ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ccb91-4320-41af-9af9-5c9ec24a9d0c",
   "metadata": {},
   "source": [
    "### <u>Dataset: TMDB Movie Reviews\n",
    "<center> <img src=\"Data-NLP/Images/IMDB.png\">\n",
    "\n",
    "#### [TMDB Movie Reviews](https://drive.google.com/file/d/1vLUzSYleJXqsjNMsq76yTQ5fmNlSHFJI/view). Ratings Range from 1 to 10</center>\n",
    "- Gathering through `tmdbsimple` pyhton wrapper for the TMDB API. To legally cite TMDB, please follow their attribution requirements, which we have [summarized here](https://docs.google.com/document/d/1LzFQDulDdQjiMuZ8sBYeDbHnN62ZWjFU_xt_4eSwVIw/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd88b86-b01f-437b-9da4-e30ff881c9c9",
   "metadata": {},
   "source": [
    "# <u>Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b9346e-668f-4623-9ff0-ee24a7581646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Increase column width\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "pd.set_option('display.max_colwidth',300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac41b6-1b05-42f3-be50-ab874ea7e10a",
   "metadata": {},
   "source": [
    "# <u> Custom Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2d2266-fe42-4889-be80-c843a529f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess_texts(\n",
    "    texts,\n",
    "    nlp=None,\n",
    "    remove_stopwords=True,\n",
    "    remove_punct=True,\n",
    "    use_lemmas=False,\n",
    "    disable=[\"ner\"],\n",
    "    batch_size=50,\n",
    "    n_process=-1,\n",
    "):\n",
    "    \"\"\"Efficiently preprocess a collection of texts using nlp.pipe()\n",
    "    Args:\n",
    "        texts (collection of strings): collection of texts to process (e.g. df['text'])\n",
    "        nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None; if None, it creates a default 'en_core_web_sm' pipe.\n",
    "        remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
    "        remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
    "        use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
    "        disable (list of strings, optional): named pipeline elements to disable. Defaults to [\"ner\"]: Used with nlp.pipe(disable=disable)\n",
    "        batch_size (int, optional): Number of texts to process in a batch. Defaults to 50.\n",
    "        n_process (int, optional): Number of CPU processors to use. Defaults to -1 (meaning all CPU cores).\n",
    "    Returns:\n",
    "        list of tokens\n",
    "    \"\"\"\n",
    "    # from tqdm.notebook import tqdm\n",
    "    from tqdm import tqdm\n",
    "    if nlp is None:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    processed_texts = []\n",
    "    for doc in tqdm(nlp.pipe(texts, disable=disable, batch_size=batch_size, n_process=n_process)):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_stopwords == True) and (token.is_stop == True):\n",
    "                # Continue the loop with the next token\n",
    "                continue\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_punct == True):\n",
    "                continue\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_space == True):\n",
    "                continue\n",
    "            \n",
    "            ## Determine final form of output list of tokens/lemmas\n",
    "            if use_lemmas:\n",
    "                tokens.append(token.lemma_.lower())\n",
    "            else:\n",
    "                tokens.append(token.text.lower())\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96e1b1c-adf5-4705-ac22-e54e4b9bf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "  # Get the classification report\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  ## Print header and report\n",
    "  header = \"-\"*70\n",
    "  print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "  print(report)\n",
    "  ## CONFUSION MATRICES SUBPLOTS\n",
    "  fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "  # create a confusion matrix  of raw counts\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "  axes[0].set_title(\"Raw Counts\")\n",
    "  # create a confusion matrix with the test data\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "  axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "  # Adjust layout and show figure\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  # Return dictionary of classification_report\n",
    "  if output_dict==True:\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report_dict\n",
    "\n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858d6409-508f-4e49-94a6-1b119a6dde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\"):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0]);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da1183-0715-4d46-bf33-41772edb6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# ax = dist.plot(20, show=False)\n",
    "# ax.set_title('Number of Occurances of Top 20 Words')\n",
    "# ax.grid(False)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('frequency_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3614576c-6b6e-4334-ab61-3308a23de8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc(doc, remove_stopwords=True, remove_punct=True, use_lemmas=False):\n",
    "    \"\"\"Temporary Fucntion - for Education Purposes (we will make something better below)\n",
    "    \"\"\"\n",
    "    tokens = [ ]\n",
    "    for token in doc:\n",
    "        # Check if should remove stopwords and if token is stopword\n",
    "        if (remove_stopwords == True) and (token.is_stop == True):\n",
    "            # Continue the loop with the next token\n",
    "            continue\n",
    "    \n",
    "        # Check if should remove stopwords and if token is stopword\n",
    "        if (remove_punct == True) and (token.is_punct == True):\n",
    "            continue\n",
    "    \n",
    "        # Check if should remove stopwords and if token is stopword\n",
    "        if (remove_punct == True) and (token.is_space == True):\n",
    "            continue\n",
    "    \n",
    "        ## Determine final form of output list of tokens/lemmas\n",
    "        if use_lemmas:\n",
    "            tokens.append(token.lemma_.lower())\n",
    "        else:\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948cb69-a1ca-4cd5-bcd5-362d8187eee5",
   "metadata": {},
   "source": [
    "# `Tasks`\n",
    "## 0) <u>Update Your Project 2 Repo\n",
    "- Create a new `Data-NLP/` folder in your project 2 repository\n",
    "- Add the dowloaded review to this new `Data-NLP/` folder.\n",
    "- Make sure you have an `` folder. If <u>not</u>, create one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9ae45-e200-44c3-b79e-40619d04c9dc",
   "metadata": {},
   "source": [
    "## 1) <u>Data Preprocessing \n",
    "- `Load and Inspect the dataset`\n",
    "    - How many reviews?\n",
    "    - What does the distribution of ratings look like?\n",
    "    - Any Null values?\n",
    "- `Use the rating column to create a new` <u>`target column`</u> `with 2 groups: high-rating and low-rating groups`\n",
    "    - We recommend defining 'High-rating' reviews as any review with a rating >=9; and 'Low-Rating' reviews as any review with a rating <=4.\n",
    "    - The middel ratings between 4 and 9 will be excluded from the analysis.\n",
    "    - You may use an alternative definition for High & Low reviews, but justify your choice in your notebook/readme\n",
    "- `Utilize NLTK & SpaCy for basic text processing including:`\n",
    "    - Removing stopwards\n",
    "    - Tokenization\n",
    "    - Lemmatization\n",
    "    - `TIPS:`\n",
    "        - Be sure to creat a custom NLP Object & disable the named entity recognizer. Otherwise, processing will take a very long time!\n",
    "        - **You will want to create several versions of the data, lemmatized, tolkenized, lemmatized joined back to one string per review, and tokenized joined back to one string per review.** This will be useful for different analysis and modeling techniques.\n",
    "- `NOTE:`you may find some artifacts during your EDA e.g. HTML code like `\"href\"`. You are allowed to drop rows from the dataset after identifying problematic trends in some of the texts. `(Hint: Remember df[col].str.contains)`\n",
    "- <u>Save your processed data frame in a `joblib` file saved in the `Data-NLP/` folder for future modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759fb8b9-be27-40a3-8573-d760cd0d914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>64ecc16e83901800af821d50</td>\n",
       "      <td>tt0118694</td>\n",
       "      <td>花樣年華</td>\n",
       "      <td>This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>57086ff5c3a3681d29001512</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>5bb5ac829251410dcb00810c</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>5f0c53a013a32000357ec505</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A very good stop-motion animation!\\r\\n\\r\\n&lt;em&gt;'Chicken Run'&lt;/em&gt;, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>64ecc027594c9400ffe77c91</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_id    imdb_id original_title  \\\n",
       "movie_id                                                       \n",
       "843       64ecc16e83901800af821d50  tt0118694           花樣年華   \n",
       "7443      57086ff5c3a3681d29001512  tt0120630    Chicken Run   \n",
       "7443      5bb5ac829251410dcb00810c  tt0120630    Chicken Run   \n",
       "7443      5f0c53a013a32000357ec505  tt0120630    Chicken Run   \n",
       "7443      64ecc027594c9400ffe77c91  tt0120630    Chicken Run   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                               review  \\\n",
       "movie_id                                                                                                                                                                                                                                                                                                                \n",
       "843       This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...   \n",
       "7443                                                      A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.   \n",
       "7443      Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...   \n",
       "7443      A very good stop-motion animation!\\r\\n\\r\\n<em>'Chicken Run'</em>, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...   \n",
       "7443      Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...   \n",
       "\n",
       "          rating  \n",
       "movie_id          \n",
       "843          7.0  \n",
       "7443         9.0  \n",
       "7443         6.0  \n",
       "7443         8.0  \n",
       "7443         7.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Data\n",
    "mr = 'Data-NLP/movie_reviews_v2.csv'\n",
    "text = pd.read_csv(mr, index_col='movie_id')\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e77a7c5-4a1e-4b68-b3e0-867baaae8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8650 entries, 0 to 8649\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   review_id       8650 non-null   object \n",
      " 1   movie_id        8650 non-null   int64  \n",
      " 2   imdb_id         8650 non-null   object \n",
      " 3   original_title  8650 non-null   object \n",
      " 4   review          8650 non-null   object \n",
      " 5   rating          7454 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 405.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff67dcd-19a7-4767-8265-178c56561167",
   "metadata": {},
   "source": [
    "Cleaing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de87fd5-736f-4bb7-b65c-361c1882d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2569fed5-8c85-4a3f-8863-783ac0a0e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id            0\n",
       "movie_id             0\n",
       "imdb_id              0\n",
       "original_title       0\n",
       "review               0\n",
       "rating            1196\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null Values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d4b02d-641f-4256-aa15-b9b923bae15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>花樣年華</td>\n",
       "      <td>This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A very good stop-motion animation!\\r\\n\\r\\n&lt;em&gt;'Chicken Run'&lt;/em&gt;, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_title  \\\n",
       "0           花樣年華   \n",
       "1    Chicken Run   \n",
       "2    Chicken Run   \n",
       "3    Chicken Run   \n",
       "4    Chicken Run   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        review  \\\n",
       "0  This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...   \n",
       "1                                                  A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.   \n",
       "2  Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...   \n",
       "3  A very good stop-motion animation!\\r\\n\\r\\n<em>'Chicken Run'</em>, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...   \n",
       "4  Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...   \n",
       "\n",
       "   rating  \n",
       "0     7.0  \n",
       "1     9.0  \n",
       "2     6.0  \n",
       "3     8.0  \n",
       "4     7.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecesary columns\n",
    "movie_reviews = df.drop(df.columns[[0, 1, 2]], axis=1)\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c08d17f6-db8d-407e-b7ab-58db8746194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8650 entries, 0 to 8649\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   original_title  8650 non-null   object \n",
      " 1   review          8650 non-null   object \n",
      " 2   rating          7454 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 202.9+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90198f67-3f24-47b9-81f7-66ee3112e1a1",
   "metadata": {},
   "source": [
    "<u>Creating new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4352bdd5-742c-4521-bbc2-41ac18486d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'com',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'else',\n",
       " 'ever',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'get',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " \"how's\",\n",
       " 'however',\n",
       " 'http',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'k',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'r',\n",
       " 'same',\n",
       " 'shall',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'therefore',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'when',\n",
       " \"when's\",\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whom',\n",
       " 'why',\n",
       " \"why's\",\n",
       " 'with',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'www',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StopWords\n",
    "from wordcloud import STOPWORDS\n",
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5ecb0-c192-47b0-8b31-750abd8084e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27521ce8-c1ed-4d21-8886-2513ffcc5873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64ecc16e83901800af821d50</td>\n",
       "      <td>843</td>\n",
       "      <td>tt0118694</td>\n",
       "      <td>花樣年華</td>\n",
       "      <td>This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[this, is, a, fine, piece, of, cinema, from, wong, kar-wai, that, tells, us, a, story, of, two, people, whom, circumstance, throws, together, -, but, not, in, a, way, you, might, expect., we, start, with, two, couples, who, move, into, a, new, building., one, a, newspaper, man, with, his, wife,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57086ff5c3a3681d29001512</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[a, guilty, pleasure, for, me, personally,, as, i, love, both, 'the, great, escape', and, most, of, the, works, i, have, seen,, over, the, years,, from, this, rightfully-esteemed, british, animation, company., highly, recommended, both, for, children, and, for, adults, who, enjoy, animation.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5bb5ac829251410dcb00810c</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[made, my, roommate, who, hates, stop-motion, animation, watched, this, in, 2018, and, even, he, had, a, good, time., it's, maybe, not, as, great, as, i, remember, thinking, it, was, when, i, was, a, little, kid,, but, it, still, holds, up, to, some, degree., _final, rating:★★★, -, i, liked, it....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f0c53a013a32000357ec505</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>A very good stop-motion animation!\\r\\n\\r\\n&lt;em&gt;'Chicken Run'&lt;/em&gt;, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[a, very, good, stop-motion, animation!, &lt;em&gt;'chicken, run'&lt;/em&gt;,, which, i, watched, a, crap, tonne, when, i, was, little, but, not, for, a, vast, number, of, years, now,, is, an, impressive, production, given, it, came, out, in, 2000., despite, a, pretty, simple, feel, to, the, film,, it's, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64ecc027594c9400ffe77c91</td>\n",
       "      <td>7443</td>\n",
       "      <td>tt0120630</td>\n",
       "      <td>Chicken Run</td>\n",
       "      <td>Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[ok,, there, is, an, huge, temptation, to, riddle, this, review, with, puns, -, but, i'm, just, going, to, say, it's, a, cracking, little, family, adventure., it's, seemingly, based, on, a, whole, range, of, classic, movies, from, the, \"great, escape\",, \"star, trek\", to, \"love, story\", with, a, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  review_id  movie_id    imdb_id original_title  \\\n",
       "0  64ecc16e83901800af821d50       843  tt0118694           花樣年華   \n",
       "1  57086ff5c3a3681d29001512      7443  tt0120630    Chicken Run   \n",
       "2  5bb5ac829251410dcb00810c      7443  tt0120630    Chicken Run   \n",
       "3  5f0c53a013a32000357ec505      7443  tt0120630    Chicken Run   \n",
       "4  64ecc027594c9400ffe77c91      7443  tt0120630    Chicken Run   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        review  \\\n",
       "0  This is a fine piece of cinema from Wong Kar-Wai that tells us a story of two people whom circumstance throws together - but not in a way you might expect. We start with two couples who move into a new building. One a newspaper man with his wife, the other a business executive and his wife. The ...   \n",
       "1                                                  A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy animation.   \n",
       "2  Made my roommate who hates stop-motion animation watched this in 2018 and even he had a good time. It's maybe not as great as I remember thinking it was when I was a little kid, but it still holds up to some degree.\\r\\n\\r\\n_Final rating:★★★ - I liked it. Would personally recommend you give it a ...   \n",
       "3  A very good stop-motion animation!\\r\\n\\r\\n<em>'Chicken Run'</em>, which I watched a crap tonne when I was little but not for a vast number of years now, is an impressive production given it came out in 2000. Despite a pretty simple feel to the film, it's a very well developed concept.\\r\\n\\r\\nThe...   \n",
       "4  Ok, there is an huge temptation to riddle this review with puns - but I'm just going to say it's a cracking little family adventure. It's seemingly based on a whole range of classic movies from the \"Great Escape\", \"Star Trek\" to \"Love Story\" with a score cannibalised from just about any/everythi...   \n",
       "\n",
       "   rating  \\\n",
       "0     7.0   \n",
       "1     9.0   \n",
       "2     6.0   \n",
       "3     8.0   \n",
       "4     7.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        tokens  \n",
       "0  [this, is, a, fine, piece, of, cinema, from, wong, kar-wai, that, tells, us, a, story, of, two, people, whom, circumstance, throws, together, -, but, not, in, a, way, you, might, expect., we, start, with, two, couples, who, move, into, a, new, building., one, a, newspaper, man, with, his, wife,,...  \n",
       "1        [a, guilty, pleasure, for, me, personally,, as, i, love, both, 'the, great, escape', and, most, of, the, works, i, have, seen,, over, the, years,, from, this, rightfully-esteemed, british, animation, company., highly, recommended, both, for, children, and, for, adults, who, enjoy, animation.]  \n",
       "2  [made, my, roommate, who, hates, stop-motion, animation, watched, this, in, 2018, and, even, he, had, a, good, time., it's, maybe, not, as, great, as, i, remember, thinking, it, was, when, i, was, a, little, kid,, but, it, still, holds, up, to, some, degree., _final, rating:★★★, -, i, liked, it....  \n",
       "3  [a, very, good, stop-motion, animation!, <em>'chicken, run'</em>,, which, i, watched, a, crap, tonne, when, i, was, little, but, not, for, a, vast, number, of, years, now,, is, an, impressive, production, given, it, came, out, in, 2000., despite, a, pretty, simple, feel, to, the, film,, it's, a,...  \n",
       "4  [ok,, there, is, an, huge, temptation, to, riddle, this, review, with, puns, -, but, i'm, just, going, to, say, it's, a, cracking, little, family, adventure., it's, seemingly, based, on, a, whole, range, of, classic, movies, from, the, \"great, escape\",, \"star, trek\", to, \"love, story\", with, a, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tolkenize\n",
    "df['tokens'] = df['review'].map(lambda doc: doc.lower().split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3eba3f4-a8d7-45e6-86e1-f5320a28cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1ada133d750>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_lite = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f5afce4-2b50-4941-b93d-5e17401cb12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1538it [00:34, 45.02it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lemmatization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmatized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_preprocess_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnlp_lite\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_lemmas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m, in \u001b[0;36mbatch_preprocess_texts\u001b[1;34m(texts, nlp, remove_stopwords, remove_punct, use_lemmas, disable, batch_size, n_process)\u001b[0m\n\u001b[0;32m     27\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m processed_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(nlp\u001b[38;5;241m.\u001b[39mpipe(texts, disable\u001b[38;5;241m=\u001b[39mdisable, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, n_process\u001b[38;5;241m=\u001b[39mn_process)):\n\u001b[0;32m     30\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;66;03m# Check if should remove stopwords and if token is stopword\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[0;32m   1617\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\language.py:1702\u001b[0m, in \u001b[0;36mLanguage._multiprocessing_pipe\u001b[1;34m(self, texts, pipes, n_process, batch_size)\u001b[0m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (_, (byte_doc, context, byte_error)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;28mzip\u001b[39m(raw_texts, byte_tuples), \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1700\u001b[0m ):\n\u001b[0;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m byte_doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1702\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mDoc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_doc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1703\u001b[0m         doc\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;241m=\u001b[39m context\n\u001b[0;32m   1704\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\tokens\\doc.pyx:1359\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.from_bytes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\tokens\\doc.pyx:1449\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.from_dict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\vocab.pyx:165\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\vocab.pyx:202\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\lang\\lex_attrs.py:145\u001b[0m, in \u001b[0;36mlower\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "df['lemmatized'] = batch_preprocess_texts(df['review'], nlp=nlp_lite,use_lemmas=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1894e0-8741-45bb-a925-0da89179247c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3ea20-b02c-4a83-8083-93fe1cb1a1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "621f4ec0-52ab-44ba-9748-baedcf2c7430",
   "metadata": {},
   "source": [
    "## <u>2) EDA and Visualizaton:\n",
    "- `Create Word Clouds to visulize the most frequent and significant words in each group`\n",
    "    - Remember, you can use this analysis to identify additional custom EDA stop words to use for visualization. (e.g. if the words are common in both groups)\n",
    "    - <u>Save your WordClouds as .png files in the 'Images/' folder in your repo.</u>\n",
    "- `Apply NLTK's` <u>`FreqDist`</u> `class to compare the frequency distribution of words in the review groups`\n",
    "    - Remember, you can use this analysis to identify additional custom EDA stop words to use for visualization. (e.g. if the words are common in both groups)\n",
    "    - <u>Save your `FreqDist` as .png files in the 'Images/' folder in your repo.</u>\n",
    "- `Perform n-grams anaysis (bigrams and trigrams)`\n",
    "    - Remember, you can use this analysis to identify additional custom stop words to use for EDA. (e.g., if the words are common in both groups)\n",
    "    - Focus on BiGrams or TriGrams, using NLTK's `BigramCollectionFinder` and BigramAssocMeasures classes(or the Trigram equivalent Finder and Measures) to explore commonly used groups of words for each rating-group.\n",
    "    - Describe any differences. What do these differences tell you?\n",
    "    - <u>Save your data frame coparison of the top ngrams for each group as a Markdown Table.</u>\n",
    "        - You can use the df.to_markdown() method to create a string version of your data frame that can be copied & pasted into a Markdown cell & your readme.\n",
    "        - <center><img src='Images/1701388160__copymarkdowndataframe.png'></center>\n",
    "- `Perform sentiment analysis to creat polarity scores according to VADER's sentiment lexicon`\n",
    "    - Compare the sentiments of high-rating and low-rating texts\n",
    "    - Compare the compound sentiment sores for high and low-rating reviews.\n",
    "    - Which review polarity scores don't match the ratings? Why do you think this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56780c8a-933d-44f3-b68b-43acf6204e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bf225-279f-4fa5-af25-fd8b2023adad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2845c5-feee-4934-b8d3-229ba79aef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# # NLTK's Word Tokenization\n",
    "# word_tokens = word_tokenize(sample_text.lower())\n",
    "# print(\"Original text: \\n\", sample_text, '\\n\\n')\n",
    "# print('Word tokens: \\n', word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fef5d4-5115-429a-8f42-6dd83a6f0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import TweetTokenizer\n",
    "# # NLTK's Tweet Tokenization\n",
    "# tweet_tokenizer = TweetTokenizer()\n",
    "# tweet_tokens = tweet_tokenizer.tokenize(sample_text.lower())\n",
    "# print(\"Original text: \\n\", sample_text, '\\n\\n')\n",
    "# print(f\"Tweet Tokens: \\n\", tweet_tokens,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55412d84-eb3d-4b38-8dad-d941bf1bd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import ngrams\n",
    "# # Define bigrams\n",
    "# bigrams = ngrams(tweet_tokens, 2)\n",
    "# # display bigrams\n",
    "# list(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cda80d-ab88-4452-adee-1cd3c2752201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define trigrams\n",
    "# trigrams = ngrams(tweet_tokens, 3)\n",
    "# # display trigrams\n",
    "# list(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba584a3-2657-4026-8ade-1d6a950f6384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe6e0c-d2e7-4032-8fc0-7065a1936f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9083d58f-6913-4b8f-87bf-f860f9fb611d",
   "metadata": {},
   "source": [
    "## <u>3) Evaluation and Reporting:\n",
    "- `Based on your anlysis, what should someone do (or not do) if they want to make a highly-rated movie?`\n",
    "    - List 3 things associated with high-rating reviews\n",
    "    - List 3 things associated with low-rating reviews \n",
    "- `Update your project README with a new Section for 'NLP Analysis of Movie Reviews.'`\n",
    "    - Include what reviews were used (source and what the original rating numbers were b4 they were converted to a categorical target)\n",
    "    - Include your EDA visualization in your README:\n",
    "        - One WordCloud comparing both groups\n",
    "        - 2 FreqDist plots(1 per group)\n",
    "        - A Markdown table of the Top Ngrams for each group.\n",
    "    - Your recommendations/conclusions for what to do/not to do make a highly-rated movie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49141d5b-8cde-4f0e-bacb-8bd7cfa4e70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5dd51c-f9b5-48f2-8a78-14e17bcf1b45",
   "metadata": {},
   "source": [
    "## <u>Deliverables:\n",
    "1. Notebook files for Preprocessing and EDA\n",
    "2. EDA Images saved in an `\"Images\"` folder.\n",
    "3. Update README "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
